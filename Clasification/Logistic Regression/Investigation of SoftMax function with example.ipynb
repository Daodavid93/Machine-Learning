{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigation of SoftMax function with example.\n",
    "author : Daodeiv (David Stankov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h7>\n",
    "        <font color='#263a61' > The softmax is a function that takes as input a vector with K real numbers, and normalizes it into a probability distribution consisting of K probabilities proportional to the exponentials of the input numbers. That is, prior to applying the softmax function, some vector components could be negative, or greater than one and might not sum to one. Futhermore, the larger input components corresponds to larger  probabilities. The softmax function is often used in neural networks to map non normalized output of the network to a probability distribution over predicted output classes.\n",
    "        <br>\n",
    "        \n",
    "             \n",
    "    \n",
    "   </font>\n",
    "</h7>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h7>\n",
    "    <font color='#454214' >\n",
    "        The standart softmax function $\\sigma: \\; \\Re^k \\; \\rightarrow \\; \\Re^k $ is defined by formula : <br>\n",
    "    \n",
    "\n",
    "   </font>    \n",
    "</h7>\n",
    "<h2><font color='#1c5cd9' > $$\\sigma(z)_i= \\frac{e^z_i}{\\sum_{j=1}^n e^{z}_{j}}$$  \n",
    "     </font> \n",
    "</h2>\n",
    "<h7>\n",
    "    <font color='#263a61' >Before getting deeper into the above equation, we gonna generate our learning data. The data consist of records contains a different type of vehicles and their sizes. The dataset is very simple and we would be able to predict from the size, what vehicle is, but in the beginning, our purpose is not to make a prediction the purpose is diving into the basic concepts behind softmax.\n",
    "    \n",
    "   </font>\n",
    "</h7>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tractor_dataframe= pd.DataFrame(data=np.random.random((30, 3))+4,columns = ['x_size','y_size','z_size'])\n",
    "plt.scatter(tractor_dataframe['x_size'],tractor_dataframe['y_size'],label='Tractor',color='blue')\n",
    "tractor_dataframe['label'] =pd.DataFrame( np.full((1,30 ), 'Tractor').T)\n",
    "\n",
    "car_dataframe= pd.DataFrame(data=np.random.random((30, 3)) + 1,columns = ['x_size','y_size','z_size'])\n",
    "plt.scatter(car_dataframe['x_size'],tractor_dataframe['y_size'],label='Car',color='red')\n",
    "car_dataframe['label'] =pd.DataFrame( np.full((1,30 ), 'Car').T)\n",
    "\n",
    "bus_dataframe= pd.DataFrame(data=np.random.random((30, 3))+2,columns = ['x_size','y_size','z_size'])\n",
    "plt.scatter(bus_dataframe['x_size'],tractor_dataframe['y_size'],label='Bus',color='yellow')\n",
    "bus_dataframe['label'] =pd.DataFrame( np.full((1,30 ), 'Bus').T)\n",
    "plt.xlabel('x size')\n",
    "plt.ylabel('y size')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "data = tractor_dataframe.append(bus_dataframe).append(car_dataframe)\n",
    "data = pd.get_dummies(data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_size</th>\n",
       "      <th>y_size</th>\n",
       "      <th>z_size</th>\n",
       "      <th>label_Bus</th>\n",
       "      <th>label_Car</th>\n",
       "      <th>label_Tractor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4.018739</td>\n",
       "      <td>4.081280</td>\n",
       "      <td>4.945429</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.089081</td>\n",
       "      <td>4.959956</td>\n",
       "      <td>4.091043</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.636914</td>\n",
       "      <td>4.308745</td>\n",
       "      <td>4.300109</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.464787</td>\n",
       "      <td>4.828882</td>\n",
       "      <td>4.774260</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4.386441</td>\n",
       "      <td>4.999404</td>\n",
       "      <td>4.073386</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.039236</td>\n",
       "      <td>1.387498</td>\n",
       "      <td>1.912427</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>1.867626</td>\n",
       "      <td>1.915900</td>\n",
       "      <td>1.681023</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>1.348552</td>\n",
       "      <td>1.763558</td>\n",
       "      <td>1.319645</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>1.791843</td>\n",
       "      <td>1.038881</td>\n",
       "      <td>1.201212</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>1.362032</td>\n",
       "      <td>1.578180</td>\n",
       "      <td>1.482176</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      x_size    y_size    z_size  label_Bus  label_Car  label_Tractor\n",
       "0   4.018739  4.081280  4.945429          0          0              1\n",
       "1   4.089081  4.959956  4.091043          0          0              1\n",
       "2   4.636914  4.308745  4.300109          0          0              1\n",
       "3   4.464787  4.828882  4.774260          0          0              1\n",
       "4   4.386441  4.999404  4.073386          0          0              1\n",
       "..       ...       ...       ...        ...        ...            ...\n",
       "25  1.039236  1.387498  1.912427          0          1              0\n",
       "26  1.867626  1.915900  1.681023          0          1              0\n",
       "27  1.348552  1.763558  1.319645          0          1              0\n",
       "28  1.791843  1.038881  1.201212          0          1              0\n",
       "29  1.362032  1.578180  1.482176          0          1              0\n",
       "\n",
       "[90 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h7>\n",
    "    <br>\n",
    "        <font color='#263a61' >\n",
    "The Label_car,label_bus, and label_tractor contain dummies values, which are categorical values transformed into convenient form in order to perform mathematical operations over them.\n",
    "   <br><br>\n",
    "   First, let separate the data into X data and Y(categorical data).         \n",
    "   </font>\n",
    "    \n",
    "</h7>                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(data.drop(['label_Bus','label_Car','label_Tractor'], axis = 1))\n",
    "y_train = np.array(data[['label_Bus','label_Car','label_Tractor']])\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_train,y_train, test_size=0.33, random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "firsts 10 elements of X: \n",
      "[[1.93804015 1.99986983 1.41626215]\n",
      " [4.78199999 4.5278506  4.12819031]\n",
      " [2.142378   2.00865232 2.27417099]\n",
      " [2.15536029 2.26510682 2.67617828]\n",
      " [4.57836866 4.6488343  4.58232809]\n",
      " [2.02076404 2.84216718 2.91191727]\n",
      " [2.36593315 2.14379695 2.49463099]\n",
      " [4.9801253  4.37838206 4.96595237]\n",
      " [1.93171614 1.26317027 1.82852311]]\n",
      "firsts 10 elements of Y: \n",
      "[[0 1 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "print('firsts 10 elements of X: ')\n",
    "print(X_train[1:10])\n",
    "print('firsts 10 elements of Y: ')\n",
    "print(y_train[1:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h7>\n",
    "    <br>\n",
    "        <font color='#263a61' > Our main purpose is to perform softmax function into $X$ values ant to get matrix(table) $I'$ which is approximately similar to $Y'$ as much as possible.In order to do that, we have to choose a matrix $Z$ consist of vectors $\\vec Z_i$ $i \\in [1,2,..,n]$ where  $n$ is number of categorical variables with $m$ components correspond to every column of the dataset , the components are also called predictors or features. Over this matrix $Z$ we have to apply softmax function. Our above dataset has a three categorical variable and three non-categorical(feature) variables , therefore we have to have matrix $Z_{(n,m+1)}=Z_{(3,4)}$ <br> <br>\n",
    "   The matrix $Z$ looks like this : <br> \n",
    "        </font> \n",
    "        <br>\n",
    "        <font color='#1c5cd9'>\n",
    "    $$ Z = \\begin{bmatrix} \\vec z_1 \\\\  \\vec z_2\\  \\\\ \\vec z_3  \\end{bmatrix} =\\begin{bmatrix} z_{11} & z_{12} & z_{13} & b_{10} \\\\ z_{21} & z_{22} & z_{23} & b_{20}\\\\ z_{31} & z_{32} & z_{33} & b_{30} \\end{bmatrix}  $$ <br> \n",
    "        </font>       \n",
    "        <br> <br>\n",
    "        <font color='#263a61' > \n",
    "         Where acording to  our dataset $z_1$ corresponds to label bus, $z_1$ to label car , $z_3$ to label tractor.\n",
    "        <br>\n",
    " If a get a dot product $K=<X|Z>+Z_0$ wich is a just matrix mutiplication : \n",
    "        </font> \n",
    "        <br> <br>\n",
    "        <font color='#1c5cd9'>\n",
    "        $$ W = K = X.Z^T =  \\begin{bmatrix} x_{11} &  x_{12} & x_{13} & 1 \\\\  x_{21} &  x_{32} & x_{33} & 1 \\\\ ... & ... & ...& ...  \\\\ x_{p1} &  x_{p2} & x_{p3} & 1  \\end{bmatrix} * \\begin{bmatrix} z_{11} & z_{21} & z_{31}  \\\\ z_{12} & z_{22} & z_{32} \\\\  z_{13} & z_{23} & z_{33}  \\\\z_{10} & z_{20} & z_{30}\\end{bmatrix}  =   \\begin{bmatrix} k_{11} &  k_{12} & k_{13} \\\\  k_{21} &  k_{32} & k_{33} \\\\ ... & ... & ...  \\\\ k_{p1} &  k_{p2} & k_{p3}  \\end{bmatrix} $$ <br> \n",
    "   </font> \n",
    "   <br>\n",
    "        <font color='#263a61' >\n",
    "        The next step is applying the softmax function over matrix K, we will call that operation the inner softmax product, wich is the core softmax concept.\n",
    "    </font> \n",
    "        <br> <br>\n",
    "        <font color='#1c5cd9'>\n",
    "        $$<Soft|K> = P(|k)= \\begin{bmatrix} \\frac{e^{k_{11}}}{\\sum_{1j}e^{k_{1j}}} & \\frac{e^{k_{12}}}{\\sum_{1j}e^{k_{1j}}} & \\frac{e^{k_{13}}}{\\sum_{1j}e^{k_{1j}}}\\\\   \\\\ ... & ... & ...  \\\\  \\\\    \\frac{e^{k_{p1}}}{\\sum_{pj}e^{k_{pj}}} & \\frac{e^{k_{p2}}}{\\sum_{pj}e^{k_{pj}}} & \\frac{e^{k_{p3}}}{\\sum_{pj}e^{k_{pj}}}\\end{bmatrix} $$ \n",
    "  </font> \n",
    "   <br> <br>\n",
    "        <font color='#263a61' >\n",
    "        The elements of $P$ we will called predictors $p_{ij}$ wich can be interpreated as probability i_th row elemenet\n",
    "        to be j_th categorical variable.If $p_{1,2}$ means what is the probability of record one belongs to the label_ bus?\n",
    "        Ofcourse, $p_{ij} \\in [0,1]$ <br>\n",
    "        Another way to express $p_{ij}$ : <br>  \n",
    "        </font> \n",
    "        <br> <br>\n",
    "      \n",
    "  </font>    \n",
    "</h7>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>\n",
    "      <font color='#1c5cd9'>\n",
    "        $$(3) \\; \\;p_{ij} = \\frac{ e^{ ^{k_{ij}} } }{ \\sum_p^3 e^{k_{ip}}}\n",
    "        =\\frac{ e^{ ^{\\sum_v^3 x_{iv}.z_{jv} }} }{ \\sum_p^3 e^{ ^ {\\sum_v^3 x_{iv}.z_{jv}}}} $$\n",
    "     </font>\n",
    "</h2>      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>\n",
    "    <br>\n",
    "        <font color='#263a61' >\n",
    "        How we can interpret the eq.(3) from probability viewpoint. If we want to find what is the probability record 2 from our dataset to be Tractor. The tractor label corresponds to $\\vec Z_3$ estimator therefore, according to the eq.(3) the probability matematicaly looks like this.\n",
    "    </font>\n",
    "     <br>\n",
    "     <br>\n",
    " </h4>\n",
    " <h2>\n",
    "     <font color='#1c5cd9'>\n",
    "         $$P(y=j|X_2) = P(y=3|X_2)=P_{23} = \\frac{ e^{ ^{k_{23}} } }{ \\sum_p^3 e^{k_{23}}}\n",
    "        =\\frac{ e^{ ^{\\sum_v^3 x_{2v}.z_{3v} }} }{ \\sum_p^3 e^{ ^ {\\sum_v^3 x_{1v}.z_{3v}}}}$$\n",
    "   </font>\n",
    "<\\h2>            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h7>\n",
    " <font color='#263a61' >\n",
    "    Let to define vector $\\vec z$ for our training set in order to apply above equation.<br>\n",
    "    The dataset has  3 categoricals and 3 features variables therefore, Z must have 3 vectors with 3 components.\n",
    "    <br> <br> \n",
    "    $$ Z = \\begin{bmatrix} \\vec z_1 \\\\  \\vec z_2\\  \\\\ \\vec z_3  \\end{bmatrix} =\\begin{bmatrix} z_{11} & z_{12} & z_{13} \\\\ z_{21} & z_{22} & z_{23} \\\\ z_{31} & z_{32} & z_{33} \\end{bmatrix}  = \\begin{bmatrix} 1 & -1.1 & 0 \\\\ -2 & -1.5 & -1 \\\\ 0.3 & 1.2 & 0.9 \\end{bmatrix} $$ <br> <br>\n",
    "  $Z$ is our predictor matrix  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = np.array([[ 1.08734519, -1.20025562, -0.28915008],\n",
    "       [-2.05135414, -1.42315072, -0.98280891],\n",
    "       [ 0.34794327,  1.28812284,  0.96695257]])\n",
    "\n",
    "Z= np.array([[ 0.75776811,  0.6690284 , -0.02646755],\n",
    " [-2.94775864, -3.06439323, -2.14043833],\n",
    " [ 2.18999053 , 2.39536483,  2.16690588]])\n",
    "\n",
    "\n",
    "intercept = np.array([ -0.15425504 , 18.81781451, -18.66355947])  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sofmax(x,Z,intercept):\n",
    "    exp_K = np.exp(x.dot(Z.T)+intercept)\n",
    "    sums=np.sum(exp_K, axis=1) # array contains sum of exp if every row\n",
    "    result = (exp_K.T/sums).T  #return for every element e^{k_ij}/(e^{k_i1}+e^{k_i2}+e^{k_i3})\n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 1 0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.25, 0.75, 0.  ],\n",
       "       [0.02, 0.  , 0.98],\n",
       "       [0.95, 0.05, 0.  ],\n",
       "       [0.87, 0.13, 0.  ],\n",
       "       [0.  , 0.  , 1.  ],\n",
       "       [0.99, 0.01, 0.  ],\n",
       "       [0.98, 0.  , 0.02],\n",
       "       [0.  , 0.  , 1.  ],\n",
       "       [0.  , 1.  , 0.  ]])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(y_train[1:10])\n",
    "np.around(sofmax(X_train,Z,intercept)[1:10],2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000000003139635"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.sum([[5.59245904e-01, 2.34001132e-04 ,1.09333100e+02], [2, 6,5]], axis=1)\n",
    "(np.array([[1,2],[4,2],[1,4]]).T*np.array([2,3,2])).T\n",
    "2.78631395e-06+ 1.36109512e-14+ 9.99997214e-01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-152-972e3e4ac3ea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mnet_in\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'net input:\\n'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnet_in\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
