{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax function,Cross Entropy Loss and Gradient descent.\n",
    "author: daodeiv (david stankov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> #454214\n",
    "    <font color='#263a61' > \n",
    "     $\\; \\; $    The softmax function that takes as an input a vector with $K$ number of component, and normalized it into  a  probability distribution consisting of  $K$ number of probabilities proportional to exponentials of input values.That is, prior to applying softmax function some vector components could be negative or greater than one and  might not sum up to 1.\n",
    "Furthermore more the larger input components correspond to larger probabilities. In this notebook mainly, our purpose is to reach the regression issue related with it using in Logistic Multiclass although the softmax is widely famous and used in neural networks.\n",
    "    <font>   \n",
    "        \n",
    "</h4>        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>\n",
    "    <font color=' #263a61 ' >\n",
    "        The standart softmax function $\\sigma: \\; \\Re^k \\; \\rightarrow \\; \\Re^k $ is defined by formula : <br>\n",
    "    \n",
    "\n",
    "   </font>    \n",
    "</h5>\n",
    "<h2><font color='#1c5cd9' > $$\\sigma(z)_i= \\frac{e^z_i}{\\sum_{j=1}^n e^{z}_{j}}$$  \n",
    "     </font> \n",
    "</h2>\n",
    "<h7>\n",
    "    <font color='#263a61' >Before getting deeper into the above equation, we gonna generate our learning data. The data consist of records contains a different type of vehicles together their sizes. The dataset is very simple since we would be able to do prediction per our brain, without using any ML concept however in the beginning, our purpose is not to make a prediction our purpose is diving into the basic concepts behind softmax underlying on math.\n",
    "    \n",
    "   </font>\n",
    "</h7>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>\n",
    "    <font color=' #263a61 ' >\n",
    "        Let's generate our data : <br>\n",
    "    \n",
    "\n",
    "   </font>    \n",
    "</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_size</th>\n",
       "      <th>y_size</th>\n",
       "      <th>z_size</th>\n",
       "      <th>label_Bus</th>\n",
       "      <th>label_Car</th>\n",
       "      <th>label_Tractor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4.263699</td>\n",
       "      <td>4.601186</td>\n",
       "      <td>4.621515</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.090017</td>\n",
       "      <td>4.056658</td>\n",
       "      <td>4.305056</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.662636</td>\n",
       "      <td>4.837471</td>\n",
       "      <td>4.571841</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.083408</td>\n",
       "      <td>4.941587</td>\n",
       "      <td>4.427719</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4.880827</td>\n",
       "      <td>4.024226</td>\n",
       "      <td>4.858753</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.967051</td>\n",
       "      <td>1.448982</td>\n",
       "      <td>1.620016</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>1.127389</td>\n",
       "      <td>1.349759</td>\n",
       "      <td>1.942478</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>1.805954</td>\n",
       "      <td>1.890520</td>\n",
       "      <td>1.917274</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>1.559497</td>\n",
       "      <td>1.874963</td>\n",
       "      <td>1.511529</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>1.225355</td>\n",
       "      <td>1.926728</td>\n",
       "      <td>1.205630</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      x_size    y_size    z_size  label_Bus  label_Car  label_Tractor\n",
       "0   4.263699  4.601186  4.621515          0          0              1\n",
       "1   4.090017  4.056658  4.305056          0          0              1\n",
       "2   4.662636  4.837471  4.571841          0          0              1\n",
       "3   4.083408  4.941587  4.427719          0          0              1\n",
       "4   4.880827  4.024226  4.858753          0          0              1\n",
       "..       ...       ...       ...        ...        ...            ...\n",
       "25  1.967051  1.448982  1.620016          0          1              0\n",
       "26  1.127389  1.349759  1.942478          0          1              0\n",
       "27  1.805954  1.890520  1.917274          0          1              0\n",
       "28  1.559497  1.874963  1.511529          0          1              0\n",
       "29  1.225355  1.926728  1.205630          0          1              0\n",
       "\n",
       "[90 rows x 6 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#generate tractor records with random size between [4,5] \n",
    "tractor_dataframe= pd.DataFrame(data=np.random.random((30, 3))+4,columns = ['x_size','y_size','z_size'])\n",
    "tractor_dataframe['label'] =pd.DataFrame( np.full((1,30 ), 'Tractor').T)\n",
    "\n",
    "#generate car records with random size between [3,4] \n",
    "car_dataframe= pd.DataFrame(data=np.random.random((30, 3)) + 1,columns = ['x_size','y_size','z_size'])\n",
    "car_dataframe['label'] =pd.DataFrame( np.full((1,30 ), 'Car').T)\n",
    "\n",
    "#generate bus records with random size between [2,3] \n",
    "bus_dataframe= pd.DataFrame(data=np.random.random((30, 3))+2,columns = ['x_size','y_size','z_size'])\n",
    "bus_dataframe['label'] =pd.DataFrame( np.full((1,30 ), 'Bus').T)\n",
    "\n",
    "# joint each data frame into  one\n",
    "data = tractor_dataframe.append(bus_dataframe).append(car_dataframe)\n",
    "data = pd.get_dummies(data) \n",
    "data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>\n",
    "    <br>\n",
    "    <font color='#454214'>\n",
    "       The label values label_car,label_bus, and label_tractor are represented as one-hot encoding variable (dummies) in order to be convenient for mathematical manipulation or just to be used in mathematical equations.\n",
    "\n",
    "   </font>    \n",
    "   <br>\n",
    "</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2a4fdcefc08>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(tractor_dataframe['x_size'],tractor_dataframe['y_size'],label='Tractor',color='blue')\n",
    "plt.scatter(car_dataframe['x_size'],tractor_dataframe['y_size'],label='Car',color='red')\n",
    "plt.scatter(bus_dataframe['x_size'],tractor_dataframe['y_size'],label='Bus',color='yellow')\n",
    "plt.xlabel('x size')\n",
    "plt.ylabel('y size')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>\n",
    "    <br>\n",
    "    <font color='#454214' >\n",
    "       The above scatter plot shows the simplicity of the classification problem because it is obvious how they are separated into classes. <br> <br>\n",
    "     </font>    \n",
    "   <br>\n",
    "</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first 3 record of x train [[4.76568573 4.23798226 4.00926078]\n",
      " [1.70021974 1.50097358 1.59699451]\n",
      " [4.66962546 4.82251261 4.20540429]\n",
      " [2.22914924 2.40629368 2.83279133]]\n",
      "first 3 record of y label  [[0 0 1]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [1 0 0]]\n",
      "shape of x train (n.m) (60, 3)\n",
      "shape of y label (n,k) (60, 3)\n"
     ]
    }
   ],
   "source": [
    "x_train = np.array(data.drop(['label_Bus','label_Car','label_Tractor'], axis = 1)) # gets the target label variables\n",
    "y_train = np.array(data[['label_Bus','label_Car','label_Tractor']]) # gets feature variables \n",
    "X_train, X_test, y_train, y_test = train_test_split(x_train,y_train, test_size=0.33, random_state=42) #separats into test and train samples \n",
    "print('first 3 record of x train', X_train[ : 4] )\n",
    "print('first 3 record of y label ', y_train[ : 4] )\n",
    "\n",
    "print('shape of x train (n.m)', X_train.shape)\n",
    "print('shape of y label (n,k)', y_train.shape )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h7>\n",
    "    <br> <br> <br>\n",
    "    <font color='#263a61'> $\\; \\; \\; $In softmax regression we replace sigmoid function by so-called softmax function \n",
    "          $\\phi_{softmax (.)}$. Where we difine the net input as :  \n",
    "          <br> <br>\n",
    "   </font>\n",
    "   <font color='#454214' >\n",
    "      $$ z = w_1 x_1 + ...+w_nx_n +b = \\sum_l^mw_lx_l +b = W^T +b$$\n",
    "   </font>\n",
    "   <br> <br>\n",
    "   <font color='#263a61'>\n",
    "     (W is the weight vector, X is is the feature of 1 training example, and b is bias unit ) <br> <br>\n",
    "    \n",
    "Now,softmax function computes the probability that this training example $x^{(i)}$ belongs to class j given the weight and net input $z^{(i)}$. <br>\n",
    "So we compute the probability $p(y=j | x^{(i)};W_j)$ for each class label in j=1,...,k..Note the normalization term in the denominator which causes these class probabilities to sum up one. <br>\n",
    "<br> <br> \n",
    "Our training sample consist of $(n_{samples} ,m_{features})$ = (60,3) and label consist of  are ( k_{classes} ) =  (3)\n",
    "therefore  the weight matrix is $m\\times k = 9$ or  $(m_{features},k_{classes}(probabilities) = (3 ,3)$ dimensional matrix.  \n",
    "\n",
    "To compute the net input $z$, we mutiply feature matrix with weight matrix  $(n_{samples} ,m_{features})\\times (m_{features} ,k_{classes})\\; (60,3)\\times(3,3) $ wich yields a $60 \\times 3 $ to wich we then add the bias unit.Mathematicaly look like this:\n",
    " </font> \n",
    "</h7>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <h5>\n",
    "    <font color='#454214' > weight vector : </font>\n",
    "  <font color='#454214' > \n",
    "     <br>  \n",
    "    $$ W= \\begin{bmatrix} weight_1\\rightarrow class \\; 1(bus) \\\\ weight_2\\rightarrow class\\;  2(car) \\;   \\\\ weight_3\\rightarrow class \\;3(tractor) \\;  \\end{bmatrix} =\n",
    "    \\begin{bmatrix} \\vec w_1 \\\\  \\vec w_2\\  \\\\ \\vec w_3  \\end{bmatrix} =\\begin{bmatrix} w_{11} & w_{12} & w_{13} \\\\ w_{21} & w_{22} & w_{23} \\\\ w_{31} & w_{32} & w_{33} \\end{bmatrix}  $$ \n",
    "   <br>\n",
    "    \n",
    "\n",
    "   \n",
    " </font>\n",
    "<h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <h5>\n",
    "  <font color='#454214' > \n",
    "        <font color='#454214' >   Bias vector : </font>\n",
    "   <br>  \n",
    "    $$ B= \\begin{bmatrix}  b_1 \\\\  b_2\\  \\\\  b_3  \\end{bmatrix}   $$ \n",
    "   <br>\n",
    "    \n",
    "\n",
    "   \n",
    " </font>\n",
    "<h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <h7>\n",
    " <br> <br>\n",
    "        <font color='#263a61' >\n",
    "            Let find some necessary derivatives: \n",
    "         </font> \n",
    "</h7>    \n",
    " <h2>\n",
    "     <font color='#454214'>\n",
    "         $\\;\\;\\;\\;\\;\\;\\;\\;  \\frac{\\partial z_{mv}}{\\partial w_{ij}} =\\frac{\\partial (x_{mp} w_{vp} + b_v)}{\\partial w_{ij}}$ <br> <br>\n",
    "       $\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;  =  \\frac{ x_{mp} \\partial w_{vp} }{\\partial w_{ij}} +\\frac{\\partial b_v}{\\partial w_{ij}} $\n",
    "  </font>\n",
    "</h2>\n",
    " <h7>\n",
    "     <br>\n",
    "     <font color='#1c5cd9' >\n",
    "          $\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\; \\;\\;\\;\\;\\;\\;\\;  \\;\\;\\;\\;\\;\\;\\;due\\; to \\; \\frac{ \\partial w_{vp} }{\\partial w_{ij}} =1\\; when \\; (v=i\\;and\\; p=j) \\;and \\;\\frac{ \\partial w_{jp} }{\\partial w_{it}}=0  \\;when \\; (v \\ne i\\;or\\; p \\ne j) \\;  we \\; could \\;introduce\\; a\\; symbol \\; \\delta\\; and \\; write \\; \\frac{ \\partial w_{jp} }{\\partial w_{it}}=\\delta_{vi}\\delta_{pj} $ \n",
    "     </font>\n",
    " </h7> \n",
    "  <h2>\n",
    "     <font color='#454214'>\n",
    "        $\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;  =   x_{mp}\\delta_{vi}\\delta_{pj} +\\frac{\\partial b_v}{\\partial w_{ij}} $ <br> <br>\n",
    "  </font>\n",
    "</h2>\n",
    "<h7>\n",
    "     <br>\n",
    "     <font color='#1c5cd9' >\n",
    "          $\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\; \\;\\;\\;\\;\\;\\;\\;  \\;\\;\\;\\;\\;\\;\\;using\\; kronicker \\;properties \\; p \\; is\\;  replaced by\\;  j \\; and\\;v \\; by\\;i  $ \n",
    "     </font>\n",
    " </h7> \n",
    "  <h2>\n",
    "     <font color='#454214'>\n",
    "        $\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;  =   x_{mj}\\delta_{ii}\\delta_{jj} +\\frac{\\partial b_v}{\\partial w_{ij}} $ <br> <br>\n",
    "       $\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;  =  \\frac{ x_{ip} \\partial w_{jp} }{\\partial w_{ij}}\\delta_{ii}\\delta_{jj} +0 $\n",
    "  </font>\n",
    "</h2>\n",
    "<h7>\n",
    "     <br>\n",
    "     <font color='#1c5cd9' >\n",
    "          $\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\; \\;\\;\\;\\;\\;\\;\\;  \\;\\;\\;\\;\\;\\;\\; i  \\; is\\;  a\\; part\\; only \\;of \\;  \\delta_{ii} therefore \\;it\\; can \\; be \\;removed \\;and \\;\\frac{\\partial b_v}{\\partial w_{ij}}=0 $ \n",
    "   </font>\n",
    " </h7> \n",
    "  <h2>\n",
    "     <font color='#454214'>\n",
    "        $\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;  =   x_{mj}\\delta_{jj} + 0 $ <br> <br>\n",
    "      $\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;  =   x_{mj} $ <br> <br>\n",
    "  </font>\n",
    "</h2>\n",
    "<h7>\n",
    "     <br>\n",
    "     <font color='#263a61' >\n",
    "         !!! The result can be proof using direct verification as well  If someone is not able to understand proof using Kronecker notations.\n",
    "   </font>\n",
    " </h7> \n",
    "  <h2>\n",
    "     <font color='#454214'>\n",
    "       $$ \\;\\;(3)\\;\\;\\;\\;\\;\\frac{\\partial z_{mv}}{\\partial w_{ij}} = x_{mj}$$\n",
    "  </font>\n",
    "</h2>\n",
    "<h7>\n",
    "     <br>\n",
    "     <font color='#263a61' >\n",
    "         In the same way can be proof for bias:\n",
    "   </font>\n",
    " </h7> \n",
    "  <h2>\n",
    "     <font color='#454214'>\n",
    "       $$ \\;\\;(4)\\;\\;\\;\\;\\;\\frac{\\partial z_{mv}}{\\partial b_{j}} = \\delta_{vj}$$\n",
    "  </font>\n",
    "</h2>\n",
    "<h7>\n",
    "     <br>\n",
    "     <font color='#263a61' >\n",
    "         Go on!!!\n",
    "   </font>\n",
    " </h7>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>\n",
    "    <br> <br>\n",
    "     <font color='#454214'>\n",
    "         $\\;\\;\\;\\;\\;\\;\\;\\; \\frac{\\partial p_{mv}}{\\partial w_{ij}} =\\frac{\\partial p_{mv}}{\\partial z_{ij}}\\times\\frac{\\partial z_{ij}}{\\partial w_{ij}} $\n",
    "    </font>\n",
    "</h2>\n",
    "<h7> \n",
    "    <br>\n",
    "     <font color='#1c5cd9' >\n",
    "          $\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\; \\;\\;\\;\\;\\;\\;\\;  \\;\\;\\;\\;\\;\\;\\;applying\\; eq.(3)\\; we \\;ahcieve  $ \n",
    "     </font>\n",
    " </h7> \n",
    " <h2>\n",
    "     <font color='#454214'>\n",
    "         $\\;\\;\\;\\;\\;\\;\\;\\; \\;\\;\\;\\;\\;\\; =\\frac{\\partial p_{mv}}{\\partial z_{ij}}.x_{ij}$\n",
    "    </font>\n",
    "</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>\n",
    "    <br> <br>\n",
    "     <font color='#454214'>\n",
    "         $\\frac{\\partial p_{mv}}{\\partial z_{ij}} = \\frac{\\partial \\Big(  \\frac{e^{^{z_{mv}}}}{\\sum_{k=1}^K e^{^{z_{mk}}}}\\Big)}   {\\partial z_{ij}}$\n",
    "   <br> <br>\n",
    "         $\\;\\;\\;\\;\\; = \\frac{1}{(\\sum_{k=1}^K e^{^{z_{mk}}})^2}\\times\\Big( \\frac{\\partial e^{z_{mv}}}{\\partial z_{ij}}\\times(\\sum_{k=1}^K e^{^{z_{mk}}}) - \\frac{\\partial (\\sum_{k=1}^K e^{^{z_{mk}}})}{\\partial z_{ij}}\\times e^{z_{mk}}\\Big) $\n",
    "   <br> <br>\n",
    "   $\\;\\;\\;\\;\\; = \\frac{1}{\\sum_{k=1}^K e^{^{z_{mk}}}}\\times\\frac{\\partial e^{z_{mv}}}{\\partial z_{ij}} - \n",
    "\\frac{1}{(\\sum_{k=1}^K e^{^{z_{mk}}})^2}\\times  \\Big(\\sum_{k=1}^K \\frac{\\partial e^{^{z_{mk}}}}{\\partial z_{ij}}\\Big)\\times e^{z_{mv}} $   $\\;\\;\\;\\;\\;$   \\\\ line 1     \n",
    "  </font>\n",
    " </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>\n",
    "    <br> <br>\n",
    "     <font color='#454214'>\n",
    "$\\;\\;\\;\\;\\; = \\frac{1}{\\sum_{k=1}^K e^{^{z_{mk}}}}\\times\\frac{\\partial e^{z_{mv}}}{\\partial z_{ij}} - \n",
    "\\frac{1}{(\\sum_{k=1}^K e^{^{z_{mk}}})^2}\\times  (\\sum_{k=1}^K  e^{^{z_{mk}}}.\\delta_{mi}\\delta_{kj})\\times e^{z_{mv}} $   $\\;\\;\\;\\;\\;$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>\n",
    "    <br> <br>\n",
    "     <font color='#454214'>\n",
    "$\\;\\;\\;\\;\\; = \\frac{1}{\\sum_{k=1}^K e^{^{z_{mk}}}}\\times e^{z_{mv}}\\delta_{mi}\\delta_{kj} - \n",
    "\\frac{1}{(\\sum_{k=1}^K e^{^{z_{mk}}})^2}\\times  (\\sum_{k=1}^K  e^{^{z_{mk}}}.\\delta_{mi}\\delta_{kj})\\times e^{z_{mv}} $   $\\;\\;\\;\\;\\;$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>\n",
    "    <br> <br>\n",
    "     <font color='#454214'>\n",
    "$\\;\\;\\;\\;\\; = \\frac{1}{\\sum_{k=1}^K e^{^{z_{mk}}}}\\times e^{z_{mv}}\\delta_{mi}\\delta_{vj}- \\frac{\\sum_{k=1}^K  e^{^{z_{mk}}}.\\delta_{mi}\\delta_{kj}}{\\sum_{k=1}^K e^{^{z_{mk}}}}\\times \\frac{e^{z_{mv}}}{\\sum_{k=1}^K e^{^{z_{mk}}}}$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h2>\n",
    "    <br> <br>\n",
    "     <font color='#454214'>\n",
    "$\\;\\;\\;\\;\\; = \\frac{1}{\\sum_{k=1}^K e^{^{z_{ik}}}}\\times e^{z_{ij}}\\delta_{ii}\\delta_{jj}- \\frac{\\sum_{k=1}^K  e^{^{z_{mk}}}.\\delta_{mi}\\delta_{kj}}{\\sum_{k=1}^K e^{^{z_{mk}}}}\\times \\frac{e^{z_{mv}}}{\\sum_{k=1}^K e^{^{z_{mk}}}}$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>\n",
    "    <br> <br>\n",
    "     <font color='#454214'>\n",
    "$ \\frac{\\sum_{k=1}^K  e^{^{z_{ij}}}.\\delta_{ii}\\delta_{jj}}{\\sum_{k=1}^K e^{^{z_{ik}}}}\\times \\frac{e^{z_{mv}}}{\\sum_{k=1}^K e^{^{z_{mk}}}} = p_{ij}p_{mv}$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\frac{\\partial p_{mv}}{\\partial z_{ij}}=p_{ij}(1-p_{mv})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " <h7>\n",
    "     <font color='#1c5cd9'>\n",
    "         <br>\n",
    "         $\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;$  if $j=t$ then $\\frac{e^{z_{ij}}}{z_{it}} = z_{ij}$ if $j\\ne t$ then  $\\frac{e^{z_{ij}}}{z_{it}}=0$ (it is simple for proving)  <br> <br>\n",
    "        $\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;$ For simplicity  as a continue we will separate the function in two cases when $j=t$ and $j\\ne t$ <br> <br>\n",
    "          $\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;$ When $j=t$ we have : <br> <br>\n",
    "     </font>\n",
    " </h7>  \n",
    " \n",
    " <h3>\n",
    "     <font color='#454214'>\n",
    "          $\\;\\;\\;\\;\\; = \\frac{z_{ij}}{\\sum_{k=1}^K e^{^{z_{ik}}}} - \\frac{1}{(\\sum_{k=1}^K e^{^{z_{ik}}})^2}\\times \\frac{\\partial e^{z_{it}}}{\\partial z_{it}}\\times e^{z_{ij}}$\n",
    "  </font>\n",
    " </h3>  \n",
    " \n",
    "  <h7>\n",
    "     <font color='#1c5cd9'>\n",
    "         <br>\n",
    "        $\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;$  According to eq(1) we could write: \n",
    "        <br> <br>\n",
    "     </font>\n",
    " </h7>  \n",
    "  <h3>\n",
    "     <font color='#454214'>\n",
    "          $\\;\\;\\;\\;\\;  = p_{ij}(1 -p_{it})$\n",
    "  </font>\n",
    " </h3>  \n",
    "  \n",
    "  <h7>\n",
    "     <font color='#1c5cd9'>\n",
    "         <br>\n",
    "        $\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;$ if $j\\ne t$ and going on from line 1, we achieve\n",
    "        <br> <br>\n",
    "     </font>\n",
    " </h7> \n",
    "  <h3>\n",
    "     <font color='#4542141'>\n",
    "          $\\;\\;\\;\\;\\; = \\frac{1}{\\sum_{k=1}^K e^{^{z_{ik}}}}\\times 0 - \n",
    "\\frac{1}{(\\sum_{k=1}^K e^{^{z_{ik}}})^2}\\times \\frac{ e^{z_{it}} }{\\partial z_{it}}\\times e^{z_{ij}} $\n",
    "          <br> <br>\n",
    "          $\\;\\;\\;\\;\\; = - \n",
    "\\frac{e^{z_{it}}}{\\sum_{k=1}^K e^{^{z_{ik}}}}\\times \\frac{e^{z_{ij}}}{\\sum_{k=1}^K e^{^{z_{ik}}}} $\n",
    "          <br> <br>\n",
    "  </font>\n",
    "  </h3>\n",
    "    <h7>\n",
    "     <font color='#1c5cd9'>\n",
    "         <br>\n",
    "         $\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;$ Again according to eq(1) we could write: \n",
    "        <br> <br>\n",
    "     </font>\n",
    " </h7> \n",
    "  <h3>\n",
    "     <font color='#454214'>\n",
    "        $\\;\\;\\;\\;\\; = -p_{ij}p_{it}$\n",
    "  </font>\n",
    "  </h3> \n",
    "  \n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h7>\n",
    "     <font color='#263a61'>\n",
    "         <br>\n",
    "         We can write : \n",
    "     </font>\n",
    " </h7>  \n",
    "  <h3>\n",
    "     <br> <br> \n",
    "    <font color='#454214'>\n",
    "$$\\frac{\\partial p_{ij}}{\\partial z_{it}} = \n",
    "\\begin{pmatrix}\n",
    "p_{ij}(1 -p_{it}) & \\;j=t  \\\\\n",
    "-p_{ij}p_{it} & j \\ne t \n",
    "\\end{pmatrix} $$\n",
    "             \n",
    "  </font>\n",
    "  </h3> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='#263a61'>\n",
    "         <br>\n",
    "         the eqution above can  be rewritten : <br> \n",
    "     </font>\n",
    " </h7>  \n",
    "   <h3>\n",
    "     <br> <br> \n",
    "    <font color='#454214'>\n",
    "        $$\\;  (4)\\; \\;\\frac{\\partial p_{ij}}{\\partial z_{it}} = p_{ij}(\\delta_{jt} - p_{it})$$ \n",
    "        <br> <br>\n",
    "        $ \\frac{\\partial z_{ij}}{\\partial w_{it}}$ \n",
    "        $=\\frac{\\partial \\sum_p^3 x_{ip} w_{jp} + b_j}{\\partial w_{it}}=x_{ij}$\n",
    "         $=\\frac{\\sum_l^3  x_{ip}\\partial w_{jp}}{\\partial w_{it}} +\\frac{\\partial b_j}{\\partial w_{it}}=x_{ij}$\n",
    "    <br> <br>\n",
    "    $$  (5)\\;\\;\\frac{\\partial z_{ij}}{\\partial w_{it}}=x_{ij}$$\n",
    "   </font>\n",
    "  </h3>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h7>\n",
    "     <font color='#263a61'>\n",
    "         <br> <br>\n",
    "         So far so good!!! <br>\n",
    "         In order to apply gradient descent we have to find all \n",
    "         Now let to find derivate of eq.(2) $ L(W,b)=-\\sum_i^n\\sum_j^k y_{ij} \\log (sofmax(Z)_{ij})$ <br> <br>\n",
    "         we have to find all $$\\nabla_{bl}L = \\frac{\\partial L}{\\partial w_{bl}}  = \n",
    " - \\sum_k\\frac{\\partial y_{ij} Log(p_{ij}) }{\\partial w_{bl}}$$\n",
    "       Applying eq (3) and using the Eistent index row we can rewrite euqtion (2) to <br>\n",
    "         $$\\nabla_{it}L = \\frac{\\partial L}{\\partial w_{it}}  = \n",
    " - \\frac{\\partial y_{ij} Log(p_{ij}) }{\\partial w_{it}}$$\n",
    "         \n",
    "  </font>\n",
    "  <h7>\n",
    " \n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>\n",
    "     <br> <br> \n",
    "    <font color='#454214'>\n",
    "$\\nabla_{it}L = \\frac{\\partial L}{\\partial w_{it}}  \n",
    "  =\\frac{\\partial y_{ij} Log(p_{ij}) }{\\partial w_{it}}  $\n",
    "  <br> <br>\n",
    "   $\\;\\;\\;\\;\\; \\;\\;\\;\\;\\;\\;\\;\\; \\;\\;\\; =\n",
    " \\frac{ y_{ij}\\partial Log(p_{ij}) }{\\partial w_{it}} = \n",
    "  \\frac{1}{p_{ij}} \\times \\frac{\\partial p_{ij}}{\\partial z_{it}} \\times \\frac{\\partial z_{ij}}{\\partial w_{it}}$\n",
    "  <br> <br>\n",
    "  $\\;\\;\\;\\;\\; \\;\\;\\;\\;\\;\\;\\;\\; \\;\\;\\; = \\frac{y_{ij}}{p_{ij}} \\times \\frac{\\partial p_{ij}}{\\partial z_{it}}\\times \\frac{\\partial z_{ij}}{\\partial w_{it}} $\n",
    "  </font>\n",
    "  </h3>  \n",
    "   <h7>\n",
    "     <font color='#1c5cd9'>\n",
    "         <br>\n",
    "         $\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;$ By applying eq.(5) and eq.(5) we will achieve: \n",
    "     </font>\n",
    " </h7> \n",
    " <h3>\n",
    "     <br> \n",
    "    <font color='#454214'>\n",
    "        $\\;\\;\\;\\;\\; \\;\\;\\;\\;\\;\\;\\;\\; \\;\\;\\; = \\frac{y_{ij}}{p_{ij}} \\times p_{ij}(\\delta_{jt} - p_{it})x_{ij} $\n",
    "      \n",
    "   <br><br>\n",
    "    $\\;\\;\\;\\;\\; \\;\\;\\;\\;\\;\\;\\;\\; \\;\\;\\; = y_{ij} \\times p_{ij}(\\delta_{jt} - p_{it}) = y_{ij}(\\delta_{jt} - p_{it})x_{ij} $\n",
    "  </font>\n",
    "  </h3>\n",
    "  <h7>\n",
    "     <font color='#1c5cd9'>\n",
    "         <br>\n",
    "         $\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;$ using Kronecker propeties we can replace symbol $t$ with $j$: then we achieve \n",
    "     </font>\n",
    " </h7> \n",
    "  <h3>\n",
    "    <br><br>\n",
    "    $\\;\\;\\;\\;\\; \\;\\;\\;\\;\\;\\;\\;\\; \\;\\;\\;  = y_{ij}(\\delta_{jj} - p_{ij})x_{ij} $\n",
    "   <br><br>\n",
    "    $\\;\\;\\;\\;\\; \\;\\;\\;\\;\\;\\;\\;\\; \\;\\;\\;  = y_{ij}(1 - p_{ij})x_{ij}$\n",
    "  </font>\n",
    "  </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h7>\n",
    "     <font color='#263a61'>\n",
    "         We achived extrmly simple eqation :\n",
    "         \n",
    "   <font>\n",
    "</h7>    \n",
    "<h2>\n",
    "    <br><br>\n",
    "      $$ \\frac{\\partial L}{\\partial w_{ij}} = y_{ij}(1 - p_{ij})x_{ij}$$ \n",
    "  </font>\n",
    "  </h2>\n",
    "<h7>\n",
    "     <font color='#263a61'>\n",
    "         For bias is just :\n",
    "         \n",
    "   <font>\n",
    "</h7> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                         <h2>\n",
    "    <br><br>\n",
    "      $$ \\frac{\\partial L}{\\partial b_{j}} = \\sum_i y_{ij}(1 - p_{ij})$$ \n",
    "  </font>\n",
    "  </h2>\n",
    "  <h7>\n",
    "     <font color='#263a61'>\n",
    "         The bias can not be fitted :\n",
    "         \n",
    "   <font>\n",
    "</h7>  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
