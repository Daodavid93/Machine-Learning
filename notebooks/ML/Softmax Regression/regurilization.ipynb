{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>\n",
    "   <font size=\"5\" face = \"Times New Roma\" color='#270336'>\n",
    "     The softmax function.Optimization problem in Cross-entropy Loss\n",
    "   </font> \n",
    " </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>\n",
    "  <p>\n",
    "    <a href =   \"https://github.com/daodavid\" > \n",
    "       <img src=\"https://cdn.thenewstack.io/media/2014/12/github-octocat.png\" align=\"left\" width=\"120\"  alt=\"daodavid\" >\n",
    "    </a>\n",
    "    <font face = \"Times New Roma\" size=\"4\"  color='#270336'>\n",
    "        author: daodeiv (David Stankov) \n",
    "    </font>\n",
    "</p>      \n",
    "</h2>   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_size</th>\n",
       "      <th>y_size</th>\n",
       "      <th>z_size</th>\n",
       "      <th>label_Bus</th>\n",
       "      <th>label_Car</th>\n",
       "      <th>label_Tractor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.264366</td>\n",
       "      <td>3.805980</td>\n",
       "      <td>3.477372</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.997451</td>\n",
       "      <td>3.115659</td>\n",
       "      <td>3.897728</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.084445</td>\n",
       "      <td>3.031143</td>\n",
       "      <td>3.715579</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.308308</td>\n",
       "      <td>3.274491</td>\n",
       "      <td>3.621352</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.313235</td>\n",
       "      <td>3.608021</td>\n",
       "      <td>3.890563</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.881612</td>\n",
       "      <td>1.594303</td>\n",
       "      <td>1.731179</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>1.894010</td>\n",
       "      <td>1.738412</td>\n",
       "      <td>1.863288</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>1.281983</td>\n",
       "      <td>1.125129</td>\n",
       "      <td>1.574829</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>1.110149</td>\n",
       "      <td>1.037065</td>\n",
       "      <td>1.258435</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>1.977658</td>\n",
       "      <td>1.879315</td>\n",
       "      <td>1.596345</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      x_size    y_size    z_size  label_Bus  label_Car  label_Tractor\n",
       "0   3.264366  3.805980  3.477372          0          0              1\n",
       "1   3.997451  3.115659  3.897728          0          0              1\n",
       "2   3.084445  3.031143  3.715579          0          0              1\n",
       "3   3.308308  3.274491  3.621352          0          0              1\n",
       "4   3.313235  3.608021  3.890563          0          0              1\n",
       "..       ...       ...       ...        ...        ...            ...\n",
       "25  1.881612  1.594303  1.731179          0          1              0\n",
       "26  1.894010  1.738412  1.863288          0          1              0\n",
       "27  1.281983  1.125129  1.574829          0          1              0\n",
       "28  1.110149  1.037065  1.258435          0          1              0\n",
       "29  1.977658  1.879315  1.596345          0          1              0\n",
       "\n",
       "[90 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#generate  records refer to tractor label with random physical size between [4,5] \n",
    "tractor_dataframe= pd.DataFrame(data=np.random.random((30, 3))+3,columns = ['x_size','y_size','z_size'])\n",
    "tractor_dataframe['label'] =pd.DataFrame( np.full((1,30 ), 'Tractor').T)\n",
    "\n",
    "#generate  records refer to car label with random physical size between [1,2]  \n",
    "car_dataframe= pd.DataFrame(data=np.random.random((30, 3)) + 1,columns = ['x_size','y_size','z_size'])\n",
    "car_dataframe['label'] =pd.DataFrame( np.full((1,30 ), 'Car').T)\n",
    "\n",
    "#generate  records refer to car label with random physical size between [2,3]  \n",
    "bus_dataframe= pd.DataFrame(data=np.random.random((30, 3))+2,columns = ['x_size','y_size','z_size'])\n",
    "bus_dataframe['label'] =pd.DataFrame( np.full((1,30 ), 'Bus').T)\n",
    "\n",
    "# joint each data frame into  one\n",
    "original_data = tractor_dataframe.append(bus_dataframe).append(car_dataframe)\n",
    "data = pd.get_dummies(original_data) \n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Tractor', 'Bus', 'Car'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_data['label'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<font size=\"4\" color='#270336' face = \"Times New Roma\">\n",
    "&nbsp;&nbsp;The class (target)  values can be Car, Bus, Tractor. In our working data, the label values are expressed as one-hot encoding variables or so-called dummies. This numerical representation of non-numerical data just allows mathematical manipulation over them.\n",
    "</font>    \n",
    "<br> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>\n",
    "     <font size=\"3\" color='#270336' face = \"Times New Roma\" >\n",
    "        &nbsp;&nbsp; Let to visualize the data  using  Scatter plot :  \n",
    "</font>    \n",
    "</h6>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x203d64bbfc8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(tractor_dataframe['x_size'],tractor_dataframe['y_size'],label='Tractor',color='blue')\n",
    "plt.scatter(car_dataframe['x_size'],tractor_dataframe['y_size'],label='Car',color='red')\n",
    "plt.scatter(bus_dataframe['x_size'],tractor_dataframe['y_size'],label='Bus',color='yellow')\n",
    "plt.xlabel('x size')\n",
    "plt.ylabel('y size')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of x train (M, N) (60, 3)\n",
      "shape of y label (M, K) (60, 3)\n"
     ]
    }
   ],
   "source": [
    "x_train = np.array(data.drop(['label_Bus','label_Car','label_Tractor'], axis = 1)) # gets the target label variables\n",
    "y_train = np.array(data[['label_Bus','label_Car','label_Tractor']]) # gets feature variables \n",
    "X_train, X_test, y_train, y_test = train_test_split(x_train,y_train, test_size=0.33, random_state=42) #separats into test and train samples \n",
    "\n",
    "print('shape of x train (M, N)', X_train.shape)\n",
    "print('shape of y label (M, K)', y_train.shape )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5 style=\"margin-right: 45px; margin-left: 45px\">\n",
    "<font size=\"3\" color='#270336' face = \"Times New Roma\">\n",
    "        &nbsp;&nbsp; Let to implement softmax function: <br>\n",
    "</font>    \n",
    "</h5>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(X, W, B):\n",
    "    '''\n",
    "    softmax function  \n",
    "    takes :\n",
    "    X = training data\n",
    "    W =  weight matrix\n",
    "    b = bias vector (intercept) \n",
    "    return :\n",
    "      softmax for every z unit e^{k_ij}/Sum(e^{k_i1}+e^{k_i2}+e^{k_i3})\n",
    "    '''\n",
    "    #dot product between X_data matrix  and tranposed Weight_ matrix added to Bias  gives matrix each z_ij\n",
    "    Z = X.dot(W.T)+B \n",
    "    \n",
    "    #return matrix cosist of exponentials Z input net\n",
    "    exp_z = np.exp(X.dot(W.T)+B)\n",
    "    \n",
    "    #array contains sum  of every row  (e^z_{ik})\n",
    "    sums=np.sum(exp_z, axis=1) \n",
    "    \n",
    "    #return softmax(Z)_{ij}\n",
    "    return (exp_z.T/sums).T \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_gradient(X,y,max_iter=300,learning_rate=0.1,innitial_value = 10, debug_W=None):\n",
    "    bias = np.full((y.shape[1],),innitial_value)\n",
    "    W = np.full((X.shape[1], y.shape[1]), innitial_value)\n",
    "    m = X.shape[0]\n",
    "    gamma = (1/m)*learning_rate\n",
    "    debug_mode = (debug_W is not None) \n",
    "    if debug_mode: debug_W = W[1]\n",
    "    \n",
    "    for i in range(max_iter):\n",
    "        B = softmax(X,W,bias)-y\n",
    "        W = W - gamma*B.T.dot(X)\n",
    "        bias =bias - gamma*np.sum(B, axis=0)\n",
    "        if debug_W is not None:\n",
    "            #debug_W = np.append(W, W[debug_W], axis=0)\n",
    "            print(debug_W)\n",
    "    \n",
    "    if debug_mode :\n",
    "        return W,bias,W\n",
    "\n",
    "    return debug_W\n",
    "\n",
    "#         if np.isnan(w_delta).any() or np.isnan(b_delta).any():\n",
    "#             warnings.warn('The iteration process has been interrupted because  some value became infinity.')\n",
    "#             break;     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fuck 10000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1.        , 1.00200547, 1.00786255, ..., 1.8964879 , 1.89648878,\n",
       "       1.89648966])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def perform_gradient(X,y,max_iter=300,learning_rate=0.1,innitial_value =1, debug_W=None):\n",
    "    \n",
    "    print('fuck',max_iter)  \n",
    "    #debug values of wieght matrix\n",
    "    debug_mode = False\n",
    "    if debug_W is not None: debug_mode=True \n",
    "    \n",
    "    bias = np.full((y.shape[1],),innitial_value)\n",
    "    W = np.full((X.shape[1], y.shape[1]), innitial_value)\n",
    "    if debug_mode:  debug = W[(debug_W)]\n",
    "    m = X.shape[0] \n",
    "    gamma = (1/m)*learning_rate\n",
    "    \n",
    "    for i in range(max_iter):\n",
    "        B = softmax(X,W,bias)-y\n",
    "        W = W - gamma*B.T.dot(X)\n",
    "        bias = bias - gamma*np.sum(B, axis=0)\n",
    "        if debug_mode: debug = np.append(debug, W[debug_W])\n",
    "    \n",
    "    if debug_mode: \n",
    "            return W,bias,debug\n",
    "    print('fuck',max_iter)    \n",
    "    return W,bias\n",
    "\n",
    "W,b,k = perform_gradient(X_train,y_train,max_iter=10**4,learning_rate=0.1,debug_W=(0,1))\n",
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original data label Y :  \n",
      "[[0 0 1]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [1 0 0]]\n",
      "\n",
      "predicted data label Y' :\n",
      "[[0.04 0.   0.96]\n",
      " [0.83 0.05 0.11]\n",
      " [0.03 0.97 0.  ]\n",
      " [0.08 0.   0.92]\n",
      " [0.05 0.   0.95]\n",
      " [0.87 0.12 0.01]\n",
      " [0.21 0.79 0.  ]\n",
      " [0.04 0.   0.96]\n",
      " [0.86 0.09 0.05]]\n"
     ]
    }
   ],
   "source": [
    "print('original data label Y :  ')\n",
    "print(y_test[1:10])\n",
    "print('')\n",
    "print(\"predicted data label Y' :\")\n",
    "print("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(1,100,len(k))\n",
    "plt.plot(x,k)\n",
    "plt.xscale('log')\n",
    "#plt.show()\n",
    "#plt.plot(x,k)\n",
    "#plt.show()\n",
    "#plt.plot(x,np.exp(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = np.linspace(1,100000,len(k))\n",
    "# plt.plot(x,k)\n",
    "# plt.xscale('log')\n",
    "# plt.show()\n",
    "# plt.plot(x,k)\n",
    "# #plt.show()\n",
    "# #plt.plot(x,np.exp(k))\n",
    "# def plot_weight(W):\n",
    "#     \"\"\"\n",
    "    \n",
    "#     \"\"\"\n",
    "fig, axs = plt.subplots(4, 4,figsize=(20,20))        \n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        learning_rate = 0.1*(i+1)*3\n",
    "        max_iter = 10**(j+1)   \n",
    "        W,b,k = perform_gradient(X_train,y_train,max_iter=max_iter,learning_rate=learning_rate,debug_W=(0,1))\n",
    "        axs[i, j].set_title('l-{} it={}'.format(learning_rate,max_iter))\n",
    "        x = np.linspace(1,100000,len(k))\n",
    "        axs[i, j].plot(x,k)\n",
    "'''\n",
    "\n",
    "  size = np.sqrt(num)  \n",
    "    a = cartesian(1,100,num)\n",
    "  \n",
    "    x = np.linspace(-10,10,30)\n",
    "    if not size.is_integer():\n",
    "        raise ValueError(\"num must has precise  root of integer type \")\n",
    "    size = int(size)\n",
    "    f\n",
    "    for i in range(size):\n",
    "        for j in range(size):\n",
    "            axs[i, j].set_title('a = {} ,b = {}'.format(i,j)  )\n",
    "            y=sigmoid(x,i,j)\n",
    "            axs[i, j].plot(x,y)\n",
    "'''        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(4, 4,figsize=(20,20))        \n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        learning_rate = 0.1*(i+1)*4\n",
    "        max_iter = 10**(j+1)   \n",
    "        W,b,k = perform_gradient(X_train,y_train,max_iter=max_iter,learning_rate=learning_rate,debug_W=(0,1))\n",
    "        axs[i, j].set_title('l-{} it={}'.format(learning_rate,max_iter))\n",
    "        x = np.linspace(1,100000,len(k))\n",
    "        axs[i, j].plot(x,k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, axs = plt.subplots(4, 4,figsize=(20,20))        \n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        learning_rate = 0.1*(i+1)*7\n",
    "        max_iter = 10**(j+1)   \n",
    "        W,b,k = perform_gradient(X_train,y_train,max_iter=max_iter,learning_rate=learning_rate,debug_W=(0,1))\n",
    "        axs[i, j].set_title('l-{} it={}'.format(learning_rate,max_iter))\n",
    "        x = np.linspace(1,100000,len(k))\n",
    "        axs[i, j].plot(x,k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W,b,k = perform_gradient(X_train,y_train,max_iter=10000,learning_rate=0.8,debug_W=(0,1))\n",
    "print('original data label Y :  ')\n",
    "print(y_train[1:20])\n",
    "print('')\n",
    "print(\"predicted data label Y' :\")\n",
    "print(np.around(softmax(X_train,W,b)[1:20],2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xscale('log')\n",
    "fig, axs = plt.subplots(4, 4,figsize=(20,20))        \n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        learning_rate = 0.1*(i+1)*4\n",
    "        max_iter = 10**(j+1)   \n",
    "        W,b,k = perform_gradient(X_train,y_train,max_iter=max_iter,learning_rate=learning_rate,debug_W=(0,1))\n",
    "        axs[i, j].set_title('l-{} it={}'.format(learning_rate,max_iter))\n",
    "        x = np.linspace(1,100000,len(k))\n",
    "        axs[i, j].plot(np.log(x),k)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n",
      "(150,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#perform_gradient(X,y,max_iter=300,learning_rate=0.1,innitial_value =1, debug_W=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#references\n",
    "https://towardsdatascience.com/epoch-vs-iterations-vs-batch-size-4dfb9c7ce9c9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://machinelearningmastery.com/understand-the-dynamics-of-learning-rate-on-deep-learning-neural-networks/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
