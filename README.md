# Machine Learning 
 

## Maths Method in Machine Learning  MMML
- ![#f03c15](https://placehold.it/15/f03c15/000000?text=+) `#f03c15`
- ![#c5f015]* *[Linear Dependence - Basic theorems and definitions](https://nbviewer.jupyter.org/github/Daodavid93/Machine-Learning/blob/master/math/Lear%20dependecy.Deffs%20and%20Theorems.ipynb)* `#c5f015`
* *![#c5f015][Linear Tranformations-some examples and definitions](https://nbviewer.jupyter.org/github/Daodavid93/Machine-Learning/blob/master/math/Linear%20Transformation.ipynb)*
 * [Einvector and eingvalues - linear algebra example - hermitian opearators(symetric) -in Progress ](https://nbviewer.jupyter.org/github/Daodavid93/Machine-Learning/blob/master/math/Eigenvalues%20and%20Eigenvectors.ipynb)
 * [Eingdecomposition - example of covariance componets composition with diagonalization in Progress](https://nbviewer.jupyter.org/github/Daodavid93/Machine-Learning/blob/master/math/Eigendecomposition%20of%20a%20covariance%20matrix.ipynb) 
 * [Taylor Approximation - Taylors series simple example and theorems](https://nbviewer.jupyter.org/github/Daodavid93/Machine-Learning/blob/master/math/Tailor%20approximation.ipynb)
 * [Langrange mutiplier - theorem](https://nbviewer.jupyter.org/github/Daodavid93/Machine-Learning/blob/master/math/Langrange%20mutipliers.ipynb) 
 * [Gradient Descent-numerical optimization](https://nbviewer.jupyter.org/github/Daodavid93/Machine-Learning/blob/master/math/gradient%20descent.ipynb)
 
 

## ML algorithms
 * [Linear Regresion - explanation and example](https://nbviewer.jupyter.org/github/Daodavid93/Machine-Learning/blob/master/Regresion%20Model/LinearRegression.ipynb)
 * Logistic Regression
 * SVM
 * PCA
 
 

 ## Some Projects and algorithms training
 * [Human Activity Predictions -SVM+PCA example](https://nbviewer.jupyter.org/github/Daodavid93/Machine-Learning/blob/master/projects/Human-Activity-Project.ipynb)
 

       
        
